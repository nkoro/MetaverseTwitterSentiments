{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YRzSPqeze5MD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c912ad42-d964-4625-b34f-86b628f52e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.10/dist-packages (4.13.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (2.27.1)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy\n",
        "!pip install textblob\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Twitter API credentials\n",
        "consumer_key = 'put yours'\n",
        "consumer_secret = 'put yours'\n",
        "access_token = 'put yours'\n",
        "access_token_secret = 'put yours'\n",
        "\n",
        "# Authenticate with Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "# Create API object\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "\n",
        "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n"
      ],
      "metadata": {
        "id": "UeYz5Qq4mx7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from requests.models import LocationParseError\n",
        "search_term = 'metaverse security'\n",
        "since_date = '2023-01-01'\n",
        "until_date = '2023-04-15'\n",
        "#location = '39.8283,-98.5795,2500km' # USA geocode\n",
        "count = 1000\n"
      ],
      "metadata": {
        "id": "_gjvfmCLnDnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n",
        "import emoji"
      ],
      "metadata": {
        "id": "gxiVtnBayCRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "!pip install demoji\n",
        "import demoji\n",
        "\n",
        "# download demoji's emoji dictionary\n",
        "demoji.download_codes()\n",
        "\n",
        "# create empty list to store data\n",
        "tweets_data = []\n",
        "\n",
        "# loop through each tweet and extract relevant information\n",
        "for tweet in tweepy.Cursor(api.search_tweets,\n",
        "                           q=search_term,\n",
        "                           #geocode=location,\n",
        "                           lang='en',\n",
        "                           #since_id=since_date,\n",
        "                           count=count).items():\n",
        "    tweet_text = tweet.text\n",
        "    tweet_user = tweet.user.screen_name\n",
        "    tweet_date = tweet.created_at\n",
        "    #tweet_location = tweet.user.location\n",
        "\n",
        "    # remove web links\n",
        "    tweet_text = re.sub(r'http\\S+', '', tweet_text)\n",
        "\n",
        "    # remove usernames and mentions\n",
        "    tweet_text = re.sub(r'@[^\\s]+', '', tweet_text)\n",
        "\n",
        "    # remove emojis\n",
        "    emoji_less_text = demoji.replace(tweet_text, \"\")\n",
        "\n",
        "    # remove extra white spaces\n",
        "    tweet_text = re.sub(r'\\s+', ' ', emoji_less_text)\n",
        "\n",
        "    # remove any remaining non-alphanumeric characters and convert to lowercase\n",
        "    tweet_text = re.sub(r'[^a-zA-Z0-9\\s]', '', tweet_text)\n",
        "    tweet_text = tweet_text.lower()\n",
        "\n",
        "    # remove non-alphanumeric characters\n",
        "    alphanumeric_text = re.sub(r'[^a-zA-Z0-9\\s]', '', emoji_less_text)\n",
        "\n",
        "    # append cleaned tweet data to tweets_data list\n",
        "    tweet_data = [tweet_text, tweet_user, tweet_date] #,tweet_location]\n",
        "    tweets_data.append(tweet_data)\n",
        "\n",
        "# create DataFrame from tweets data\n",
        "df = pd.DataFrame(data=tweets_data, columns=['text', 'user', 'date']) #, 'location'])\n"
      ],
      "metadata": {
        "id": "RwADGbne2dHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "d6B5OEPn37sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# add sentiment polarity and subjectivity columns to the dataframe\n",
        "df['polarity'] = df['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
        "df['subjectivity'] = df['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)\n",
        "\n",
        "# classify tweets as positive, negative, or neutral based on polarity scores\n",
        "df['sentiment'] = df['polarity'].apply(lambda score: 'positive' if score > 0 else ('negative' if score < 0 else 'neutral'))\n"
      ],
      "metadata": {
        "id": "XcmH95O77omC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "oGZLS6zl5pxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of tweets for each sentiment\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "\n",
        "# calculate the percentage of tweets for each sentiment\n",
        "positive_percentage = sentiment_counts['positive'] / len(df) * 100\n",
        "negative_percentage = sentiment_counts['negative'] / len(df) * 100\n",
        "neutral_percentage = sentiment_counts['neutral'] / len(df) * 100\n",
        "\n",
        "print(\"Positive tweets percentage:\", positive_percentage)\n",
        "print(\"Negative tweets percentage:\", negative_percentage)\n",
        "print(\"Neutral tweets percentage:\", neutral_percentage)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the sentiment distribution\n",
        "sentiment_counts.plot.bar()\n",
        "\n",
        "# add titles and labels to the plot\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F3R-_O1r-xJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# define X (features) and y (target) variables\n",
        "X = df['text']\n",
        "y = df['sentiment']\n",
        "\n",
        "# split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# vectorize the text data using TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# define the LGB classifier model\n",
        "lgb_clf = lgb.LGBMClassifier()\n",
        "\n",
        "# train the model on the training data\n",
        "lgb_clf.fit(X_train_vec, y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred = lgb_clf.predict(X_test_vec)\n",
        "\n",
        "# calculate accuracy score\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {acc}\")\n"
      ],
      "metadata": {
        "id": "TkyGubVI7wld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create a string containing all the tweets\n",
        "all_tweets = ' '.join(df['text'].tolist())\n",
        "\n",
        "# generate a wordcloud plot\n",
        "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=10).generate(all_tweets)\n",
        "\n",
        "# plot the wordcloud\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sHFD5n7c8V25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "iLu8DOQu5xeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n"
      ],
      "metadata": {
        "id": "-ciFEOnJRRey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('metaverse_security_crappedtweets.csv', index=False)\n"
      ],
      "metadata": {
        "id": "rhndVoWuRR98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sc9LRcVFT3gi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}